<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
    integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.7/dist/umd/popper.min.js"
    integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/js/bootstrap.min.js"
    integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
    crossorigin="anonymous"></script>
  <link type="text/css" rel="stylesheet" href="styles.css">
  <title>Literature Review</title>
  <link rel="shortcut icon" href="images/favicon.png" type="image/x-icon">
</head>

<body>
  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top">
    <a class="navbar-brand" href="index.html">Tarik Jaber's ePortfolio</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
      aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse justify-content-end" id="navbarNav">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reflection.html">Reflection</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="research.html">Research Essay</a>
        </li>
        <li class="nav-item active">
          <a class="nav-link" href="literature.html">Literature Review</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="rhetorical.html">Rhetorical Analysis of a Visual Text</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="other.html">Other Writing</a>
        </li>
      </ul>
    </div>
  </nav>

  <div class="body">
    <h1>Literature Review</h1>
    <p>
      Tarik Jaber<br>
      ENG 1201<br>
      Professor Monroe<br>
      19 March 2023
    </p>
    <h2 class="title">Literature Review</h2>
    <p>
      Generative AI is a subfield of artificial intelligence that involves the use of machine learning algorithms to create
      new, original data based on patterns in existing data. This technology has seen tremendous progress in recent years,
      thanks to advancements in deep learning and natural language processing. This technology can have a profound impact on
      many areas of our lives. As a result, I want to pose the question: What are the potential future applications of
      generative AI, and what impacts might they have on society in areas such as healthcare, transportation, and education?
    </p>
    <p>
      Generative AI is a field of artificial intelligence that has its origins in the 1960s with the creation of the ELIZA
      computer program. In the 1980s and 1990s, researchers explored the use of neural networks for generative tasks, but
      progress was limited by computational power and data availability. With the emergence of deep learning techniques and
      larger datasets in the early 2010s, generative AI made significant progress, culminating in the introduction of
      generative adversarial networks (GANs) in 2014. Today, generative AI is advancing rapidly, with researchers exploring
      its applications in various fields. However, ethical and societal concerns, such as the potential for biased data and
      privacy violations, must be considered.
    </p>
    <p>
      "Ai 2041" by Kai-Fu Lee and Chen Qiufan is a book that explores the impact of artificial intelligence on society in
      2041. The authors discuss potential benefits and challenges in areas such as healthcare, education, transportation, and
      the workplace, as well as the risks of AI, such as job displacement and economic inequality. The book presents scenarios
      of how AI may shape society and emphasizes the need for responsible development and ethical considerations. It offers a
      thought-provoking exploration of the future of AI and its potential impact on humanity. It is overall optimistic in its
      description of AI but also has caution surrounding it. Kai-Fu Lee is the owner of Sinovation Ventures, a venture capital
      firm that invests in technology companies, so the book is likely to be more optimistic on AI.
    </p>
    <p>
      “So what if ChatGPT wrote it?” discusses the potential of AI tools like ChatGPT, which can produce human-like text and
      have various applications in industries like banking, tourism, and IT, among others. However, it also highlights the
      ethical and legal challenges that come with their use, including privacy concerns, biases, and misinformation. The
      authors suggest that further research is necessary to examine these issues and explore the optimal ways to integrate
      generative AI with human activities in various contexts. The article presents questions that require further research in
      areas such as knowledge, transparency, ethics, digital transformation, teaching, learning, and scholarly research.
    </p>
    <p>
      The CNN article discusses how Google and Microsoft are vying to change how people search for information online using
      generative AI, the technology behind ChatGPT. The AI draws on vast amounts of online information to generate written
      responses to user prompts and queries. The article mentions how both companies have unveiled their plans to incorporate
      AI into their search engines, with Microsoft testing a new version of Bing that creates written summaries of search
      results and chats with users to answer additional questions, among other functions. However, it further mentions how
      there are AI ethicists warning of unintended consequences, including the spread of misinformation. CNN is not a
      scholarly journal so their information will not be peer reviewed.
    </p>
    <p>
      The Washington Post article mentions how ChatGPT has been used by cybercriminals to write malware, phishing lures and
      misinformation, according to a report from Recorded Future. The article then mentioned how the technology enabled the
      creation of functional malware within days of its launch two months ago. The report by Recorded Future concluded that
      with further development of artificial intelligence models like ChatGPT, bad actors may be provided with new avenues to
      assemble code or other malicious infrastructure. Washing Post is a top tier newspaper but not a scholarly journal.
    </p>
    <p>
      The DeepMind article mentions how Generative AI has the potential to be a general-purpose technology, useful for a
      multitude of applications that span many corners of the economy, just like deep learning and electricity, according to a
      recent op-ed in VentureBeat. It offers huge opportunities for AI engineers to build applications that make the world a
      better place. The article highlights that things like writing and graphics that once were in limited supply will become
      abundant with Gen AI. The author believes there's important work to be done in coming years to identify use cases and
      build specific applications. Meanwhile, the article points out that The Washington Post reports that employers are
      hiring prompt engineers to write natural-language prompts for AI models, while also highlighting that the black-box
      nature of generative AI models based on neural networks means prompt engineering can't produce reliable results.
      DeepMind is a British artificial intelligence research company so their articles should be taken with a grain of salt as
      it is in their interest to present AI in a positive light.
    </p>
    <p>
      The use of generative AI like ChatGPT raises ethical and legal challenges, which are emphasized in "Ai 2041," "So what
      if ChatGPT wrote it?" and The Washington Post article. The CNN article warns of the unintended consequences of AI,
      including the spread of misinformation, while the DeepMind article highlights the potential of generative AI to make the
      world a better place. There is also disagreement about the extent to which generative AI can replace human activities,
      with the CNN article highlighting the use of AI to evaluate search results, but also relying on human evaluators to
      ensure quality. Further research is necessary to examine the ethical and legal challenges, biases, and misinformation
      associated with the integration of generative AI with human activities.
    </p>
    <p>
      Generative AI has the potential to revolutionize various industries, including healthcare, transportation, and
      education, by creating new, original data based on patterns in existing data. However, there are ethical and legal
      challenges associated with the use of generative AI, including privacy concerns, biases, and misinformation. "Ai 2041,"
      "So what if ChatGPT wrote it?" and The Washington Post article emphasizes the need for responsible development and
      ethical considerations. Meanwhile, the CNN article highlights the potential of AI to change how people search for
      information online, but also warns of the unintended consequences of AI, including the spread of misinformation. The
      DeepMind article sees generative AI as a general-purpose technology that can make the world a better place, but also
      acknowledges the challenges associated with its use. Further research is necessary to examine the potential impact of
      generative AI on society and to identify optimal ways to integrate it with human activities while minimizing its risks.
    </p>
    <h2>Works Cited</h2>
    <p>
      Dwivedi, Yogesh K., et al. “‘So What If ChatGPT Wrote It?’ Multidisciplinary Perspectives on Opportunities, Challenges
      and Implications of Generative Conversational AI for Research, Practice and Policy.” International Journal of
      Information Management, vol. 71, Aug. 2023. EBSCOhost, https://doi.org/10.1016/j.ijinfomgt.2023.102642.<br><br>
      Lee, K.-F., & Chen, Q. (2021). AI 2041 : ten visions for our future (First edition.). Currency.<br><br>
      Ng, Andrew. “Issue 190.” Public Attitudes Toward AI, Wanted: Prompt Engineers, and More, Public Attitudes Toward AI,
      Wanted: Prompt Engineers, and More, 31 Mar. 2023, https://www.deeplearning.ai/the-batch/issue-190/.<br><br>
      “Welcome to the 'generative AI' era. Resistance is futile." CNN Wire, 9 Feb. 2023, p. NA. Gale In Context: Opposing
      Viewpoints, link.gale.com/apps/doc/A736294985/OVIC?u=dayt30401&sid=bookmarkOVIC&xid=9590323e. Accessed 2 Apr. 2023.<br><br>
      “Yes, ChatGPT can write malicious code -- but not well." Washingtonpost.com, 26 Jan. 2023, p. NA. Gale In Context:
      Opposing Viewpoints, link.gale.com/apps/doc/A734782617/OVIC?u=dayt30401&sid=bookmarkOVIC&xid=5d6df644. Accessed 2 Apr.
      2023.
    </p>
  </div>
</body>

</html>
